{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deepWordBug.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNWEvdzjd/L9w9r5IGoAmmu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vlasovets/nlp_adversarial_examples/blob/master/deepWordBug.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4TF3gzUeWgE",
        "colab_type": "code",
        "outputId": "51df25fc-cab4-4bfb-c2b0-c38ab9747409",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "!git clone https://github.com/QData/deepWordBug.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'deepWordBug'...\n",
            "remote: Enumerating objects: 8, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 4711 (delta 1), reused 0 (delta 0), pack-reused 4703\u001b[K\n",
            "Receiving objects: 100% (4711/4711), 119.67 MiB | 29.81 MiB/s, done.\n",
            "Resolving deltas: 100% (989/989), done.\n",
            "Checking out files: 100% (3968/3968), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzAb_PTak3uX",
        "colab_type": "text"
      },
      "source": [
        "Extract all subfolders into the main root after you clone the directory; the adversarials are dependent on the task of the text used, e.g. for IMDB the adversarial will be wrong rank of the review (see gif); to change the data - change the index in [0-7] and unzip according .gz file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGLoX4-ye9Z3",
        "colab_type": "code",
        "outputId": "bdfb0c37-e0da-45bd-9e9c-102c9a40ebab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!cd ./deepWordBug\n",
        "!ls\n",
        "#!tar -xvf ag_news_csv.tar.gz\n",
        "!python attack_interactive.py --data 0"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "about\t\t       dataloader.py  models\t\tscoring.py\n",
            "ag_news_csv\t       deepWordBug    preprocessing.py\ttextdata\n",
            "ag_news_csv.tar.gz     dict\t      __pycache__\ttrain.py\n",
            "attack_interactive.py  loaddata.py    sample_data\ttransformer_char.py\n",
            "attack.py\t       model.py       scoring_char.py\ttransformer.py\n",
            "smallRNN(\n",
            "  (embd): Embedding(20000, 100)\n",
            "  (lstm): LSTM(100, 100)\n",
            "  (linear): Linear(in_features=100, out_features=4, bias=True)\n",
            "  (log_softmax): LogSoftmax()\n",
            ")\n",
            "Type input:\n",
            "sport\n",
            "/content/model.py:100: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  x = self.log_softmax(self.linear(x))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "sport\n",
            "original: Sports\n",
            "s—Äort\n",
            "adversarial: Sports\n",
            "Type next input(Enter to exit):\n",
            "news\n",
            "news\n",
            "original: Business\n",
            "new—ï\n",
            "adversarial: Sports\n",
            "Type next input(Enter to exit):\n",
            "Business\n",
            "Business\n",
            "original: Business\n",
            "busin–µss\n",
            "adversarial: Sports\n",
            "Type next input(Enter to exit):\n",
            "this year was very depressive \n",
            "this year was very depressive \n",
            "original: World\n",
            "ùöùhis year wa—ï very depressive \n",
            "adversarial: World\n",
            "Type next input(Enter to exit):\n",
            "hello, my name is Oleg, I have no idea what this code does\n",
            "hello, my name is Oleg, I have no idea what this code does\n",
            "original: Sci/Tech\n",
            "hello, my name is oleg, —ñ have no idea what this c–æde does\n",
            "adversarial: World\n",
            "Type next input(Enter to exit):\n",
            "today the stocks of apple went down\n",
            "today the stocks of apple went down\n",
            "original: Business\n",
            "today the st–æcks of apple we’∏t down\n",
            "adversarial: Sci/Tech\n",
            "Type next input(Enter to exit):\n",
            "the main star of Ranger hit three scores last game\n",
            "the main star of Ranger hit three scores last game\n",
            "original: World\n",
            "the main star of ranger hiùöù three sco‚≤Öes last game\n",
            "adversarial: Sports\n",
            "Type next input(Enter to exit):\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}